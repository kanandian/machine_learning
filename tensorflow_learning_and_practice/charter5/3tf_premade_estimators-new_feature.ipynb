{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# 读取csv文件成为pandas的DataFrame\n",
    "train_file = './data/titanic/train.csv'\n",
    "eval_file = './data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())  # head函数去除前几条数据，默认前5条\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')  # pop函数可以把相应的字段从数据集里去除，并返回该字段的值\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "train_df.describe()  #显示统计信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 使用feature columns对数据做封装\n",
    "# 将数据分为离散特征和连续特征\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']   # 离散特征\n",
    "numeric_columns = ['age', 'fare']   # 连续特征\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()   # unique函数获取一个属性所有可能的值\n",
    "    print(categorical_column, vocab)\n",
    "    feature_column = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(categorical_column, vocab))\n",
    "    feature_columns.append(feature_column)\n",
    "\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(numeric_column, dtype=tf.float32))\n",
    "    \n",
    "\n",
    "\n",
    "# cross feature: 对离散特征做笛卡尔乘积\n",
    "# hash_bucket_size=100: 10000个数据 -> hash(10000 values) % 100 重用某些值\n",
    "feature_columns.append(tf.feature_column.indicator_column(tf.feature_column.crossed_column(['age', 'sex'], hash_bucket_size=100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建dataset\n",
    "def make_dataset(data_df, label_df, epochs=10, shuffle=True, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用预先定义的estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline_estimator:根据结果比例随机猜测结果：准确率很低，只有基准水平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'baseline_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x14fec6110>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into baseline_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 22.18071, step = 0\n",
      "INFO:tensorflow:global_step/sec: 171.955\n",
      "INFO:tensorflow:loss = 21.170156, step = 100 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.956\n",
      "INFO:tensorflow:loss = 22.557037, step = 200 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.084\n",
      "INFO:tensorflow:loss = 18.17364, step = 300 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.861\n",
      "INFO:tensorflow:loss = 23.395485, step = 400 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.37\n",
      "INFO:tensorflow:loss = 19.330334, step = 500 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.517\n",
      "INFO:tensorflow:loss = 21.178625, step = 600 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.396\n",
      "INFO:tensorflow:loss = 21.62981, step = 700 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.912\n",
      "INFO:tensorflow:loss = 21.181269, step = 800 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.02\n",
      "INFO:tensorflow:loss = 21.641335, step = 900 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.633\n",
      "INFO:tensorflow:loss = 19.863045, step = 1000 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.423\n",
      "INFO:tensorflow:loss = 23.034231, step = 1100 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.666\n",
      "INFO:tensorflow:loss = 21.172455, step = 1200 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.453\n",
      "INFO:tensorflow:loss = 20.195984, step = 1300 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.596\n",
      "INFO:tensorflow:loss = 22.14723, step = 1400 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.022\n",
      "INFO:tensorflow:loss = 23.04159, step = 1500 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.005\n",
      "INFO:tensorflow:loss = 21.655628, step = 1600 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.811\n",
      "INFO:tensorflow:loss = 20.307457, step = 1700 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.298\n",
      "INFO:tensorflow:loss = 22.096134, step = 1800 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.462\n",
      "INFO:tensorflow:loss = 21.179825, step = 1900 (0.193 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into baseline_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.083973.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.baseline.BaselineClassifier at 0x14ff26d10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建输出模型的文件夹\n",
    "output_dir = 'baseline_model_new_features'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# 创建estimator\n",
    "baseline_estimator = tf.compat.v1.estimator.BaselineClassifier(model_dir=output_dir, n_classes=2)\n",
    "baseline_estimator.train(input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T17:23:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from baseline_model_new_features/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-17:23:26\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.625, accuracy_baseline = 0.625, auc = 0.5, auc_precision_recall = 0.6875, average_loss = 0.66199076, global_step = 1960, label/mean = 0.375, loss = 12.483254, precision = 0.0, prediction/mean = 0.3892243, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: baseline_model_new_features/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.625,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.5,\n",
       " 'auc_precision_recall': 0.6875,\n",
       " 'average_loss': 0.66199076,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 12.483254,\n",
       " 'precision': 0.0,\n",
       " 'prediction/mean': 0.3892243,\n",
       " 'recall': 0.0,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_estimator.evaluate(input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False, batch_size=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x150123e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/macpro/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 86.1311\n",
      "INFO:tensorflow:loss = 0.47320718, step = 100 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.623\n",
      "INFO:tensorflow:loss = 0.63504046, step = 200 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.393\n",
      "INFO:tensorflow:loss = 0.5076453, step = 300 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.554\n",
      "INFO:tensorflow:loss = 0.3114633, step = 400 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.652\n",
      "INFO:tensorflow:loss = 0.27967185, step = 500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.544\n",
      "INFO:tensorflow:loss = 0.64653754, step = 600 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.382\n",
      "INFO:tensorflow:loss = 0.45080668, step = 700 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.894\n",
      "INFO:tensorflow:loss = 0.3292954, step = 800 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.525\n",
      "INFO:tensorflow:loss = 0.4501865, step = 900 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.742\n",
      "INFO:tensorflow:loss = 0.2954587, step = 1000 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.019\n",
      "INFO:tensorflow:loss = 0.28852105, step = 1100 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.161\n",
      "INFO:tensorflow:loss = 0.54695904, step = 1200 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.998\n",
      "INFO:tensorflow:loss = 0.4703054, step = 1300 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.856\n",
      "INFO:tensorflow:loss = 0.32373023, step = 1400 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.506\n",
      "INFO:tensorflow:loss = 0.49628115, step = 1500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.827\n",
      "INFO:tensorflow:loss = 0.4433639, step = 1600 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.717\n",
      "INFO:tensorflow:loss = 0.2732222, step = 1700 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.865\n",
      "INFO:tensorflow:loss = 0.2753887, step = 1800 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.205\n",
      "INFO:tensorflow:loss = 0.55728614, step = 1900 (0.265 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.30622032.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x14feb4b10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_dir = 'linear_model_new_features'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "linear_estimator = tf.estimator.LinearClassifier(model_dir=linear_output_dir, n_classes=2,feature_columns=feature_columns)\n",
    "linear_estimator.train(input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T17:23:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model_new_features/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-17:23:39\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.8030303, accuracy_baseline = 0.625, auc = 0.85353535, auc_precision_recall = 0.77219665, average_loss = 0.4621267, global_step = 1960, label/mean = 0.375, loss = 0.44653857, precision = 0.7196262, prediction/mean = 0.4136529, recall = 0.7777778\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model_new_features/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8030303,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.85353535,\n",
       " 'auc_precision_recall': 0.77219665,\n",
       " 'average_loss': 0.4621267,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.44653857,\n",
       " 'precision': 0.7196262,\n",
       " 'prediction/mean': 0.4136529,\n",
       " 'recall': 0.7777778,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './dnn_model_new_features', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x151f8d510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./dnn_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7394173, step = 0\n",
      "INFO:tensorflow:global_step/sec: 82.4869\n",
      "INFO:tensorflow:loss = 0.48602033, step = 100 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.044\n",
      "INFO:tensorflow:loss = 0.20090169, step = 200 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.788\n",
      "INFO:tensorflow:loss = 0.25595695, step = 300 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.672\n",
      "INFO:tensorflow:loss = 0.19732714, step = 400 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.93\n",
      "INFO:tensorflow:loss = 0.39498794, step = 500 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.169\n",
      "INFO:tensorflow:loss = 0.19009548, step = 600 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.751\n",
      "INFO:tensorflow:loss = 0.4225722, step = 700 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.625\n",
      "INFO:tensorflow:loss = 0.31890696, step = 800 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.788\n",
      "INFO:tensorflow:loss = 0.30573386, step = 900 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.141\n",
      "INFO:tensorflow:loss = 0.18708041, step = 1000 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.515\n",
      "INFO:tensorflow:loss = 0.2614224, step = 1100 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.311\n",
      "INFO:tensorflow:loss = 0.2901991, step = 1200 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.408\n",
      "INFO:tensorflow:loss = 0.10600418, step = 1300 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.651\n",
      "INFO:tensorflow:loss = 0.10194735, step = 1400 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.439\n",
      "INFO:tensorflow:loss = 0.13861173, step = 1500 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.392\n",
      "INFO:tensorflow:loss = 0.23799211, step = 1600 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.814\n",
      "INFO:tensorflow:loss = 0.08396455, step = 1700 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.845\n",
      "INFO:tensorflow:loss = 0.13063662, step = 1800 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.692\n",
      "INFO:tensorflow:loss = 0.31954792, step = 1900 (0.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into ./dnn_model_new_features/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.33495188.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x14e562b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_output_dir = './dnn_model_new_features'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "dnn_estimator = tf.estimator.DNNClassifier(model_dir=dnn_output_dir,\n",
    "                                          n_classes=2,\n",
    "                                          feature_columns=feature_columns,\n",
    "                                          hidden_units=[128, 128],\n",
    "                                          activation_fn=tf.nn.relu,\n",
    "                                          optimizer='Adam')\n",
    "dnn_estimator.train(input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-10T17:23:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./dnn_model_new_features/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-10-17:23:55\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7651515, accuracy_baseline = 0.625, auc = 0.84224063, auc_precision_recall = 0.7689828, average_loss = 0.7535511, global_step = 1960, label/mean = 0.375, loss = 0.7099272, precision = 0.6456693, prediction/mean = 0.48345563, recall = 0.82828283\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: ./dnn_model_new_features/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7651515,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.84224063,\n",
       " 'auc_precision_recall': 0.7689828,\n",
       " 'average_loss': 0.7535511,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.7099272,\n",
       " 'precision': 0.6456693,\n",
       " 'prediction/mean': 0.48345563,\n",
       " 'recall': 0.82828283,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (machine_learning)",
   "language": "python",
   "name": "pycharm-b74d5558"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
