{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# 读取csv文件成为pandas的DataFrame\n",
    "train_file = './data/titanic/train.csv'\n",
    "eval_file = './data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())  # head函数去除前几条数据，默认前5条\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')  # pop函数可以把相应的字段从数据集里去除，并返回该字段的值\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "train_df.describe()  #显示统计信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15523a590>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins=20)   # 查看所有人的年龄分布：hist函数可以绘制直方图，bins参数表示柱子的条数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x155284390>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind='barh') # 显示男女数量,kind='barh'表示横向柱状图，纵向是barv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15124c410>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')   # 显示仓位人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x151284790>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示男性有多少人获救，女性有多少人获救\n",
    "pd.concat([train_df, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh') # 合并后根据性别分组，然后求是否获救的均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 使用feature columns对数据做封装\n",
    "# 将数据分为离散特征和连续特征\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']   # 离散特征\n",
    "numeric_columns = ['age', 'fare']   # 连续特征\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()   # unique函数获取一个属性所有可能的值\n",
    "    print(categorical_column, vocab)\n",
    "    feature_column = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(categorical_column, vocab))\n",
    "    feature_columns.append(feature_column)\n",
    "\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建dataset\n",
    "def make_dataset(data_df, label_df, epochs=10, shuffle=True, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=32029, shape=(5,), dtype=string, numpy=array([b'female', b'male', b'female', b'female', b'male'], dtype=object)>, 'age': <tf.Tensor: id=32021, shape=(5,), dtype=float64, numpy=array([28., 39., 24., 24., 23.])>, 'n_siblings_spouses': <tf.Tensor: id=32027, shape=(5,), dtype=int32, numpy=array([1, 1, 0, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: id=32028, shape=(5,), dtype=int32, numpy=array([0, 5, 0, 0, 0], dtype=int32)>, 'fare': <tf.Tensor: id=32026, shape=(5,), dtype=float64, numpy=array([51.8625, 31.275 , 13.    , 83.1583, 10.5   ])>, 'class': <tf.Tensor: id=32023, shape=(5,), dtype=string, numpy=array([b'First', b'Third', b'Second', b'First', b'Second'], dtype=object)>, 'deck': <tf.Tensor: id=32024, shape=(5,), dtype=string, numpy=array([b'D', b'unknown', b'unknown', b'C', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: id=32025, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: id=32022, shape=(5,), dtype=string, numpy=array([b'n', b'n', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([1 0 0 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 数据展示\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[ 29.       0.       1.       0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       1.       0.\n",
      "    0.       0.     211.3375   0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.    ]\n",
      " [ 28.       0.       1.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.       8.05     0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 31.       0.       1.       0.       0.       1.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      10.5      0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 48.       1.       0.       0.       1.       0.       0.       1.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      52.       1.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 45.       1.       0.       0.       0.       1.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.      26.25     1.       0.       0.       0.       0.\n",
      "    0.       0.       0.       1.       0.       0.       0.       0.\n",
      "    0.       1.    ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature 将feature_columns应用到dataset\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建keras模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 18 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 3s 140ms/step - loss: 0.7203 - accuracy: 0.6319 - val_loss: 0.7522 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7009 - accuracy: 0.6562 - val_loss: 0.6744 - val_accuracy: 0.6797\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6795 - accuracy: 0.6858 - val_loss: 0.5867 - val_accuracy: 0.6758\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6610 - accuracy: 0.6649 - val_loss: 0.5874 - val_accuracy: 0.6953\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5860 - accuracy: 0.7153 - val_loss: 0.5690 - val_accuracy: 0.7305\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5519 - accuracy: 0.7205 - val_loss: 0.5535 - val_accuracy: 0.7070\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5501 - accuracy: 0.7483 - val_loss: 0.5215 - val_accuracy: 0.7617\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.7413 - val_loss: 0.5261 - val_accuracy: 0.7539\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.7552 - val_loss: 0.5280 - val_accuracy: 0.7266\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.7951 - val_loss: 0.5030 - val_accuracy: 0.7578\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7695\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7695\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.8021 - val_loss: 0.4699 - val_accuracy: 0.7734\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.8108 - val_loss: 0.4712 - val_accuracy: 0.7734\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.8160 - val_loss: 0.4940 - val_accuracy: 0.7773\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4639 - accuracy: 0.7951 - val_loss: 0.4658 - val_accuracy: 0.7617\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8229 - val_loss: 0.5200 - val_accuracy: 0.7539\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8281 - val_loss: 0.4642 - val_accuracy: 0.7773\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8333 - val_loss: 0.4666 - val_accuracy: 0.7695\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8438 - val_loss: 0.4591 - val_accuracy: 0.7891\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7695\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7847 - val_loss: 0.4868 - val_accuracy: 0.7734\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7951 - val_loss: 0.5583 - val_accuracy: 0.7617\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7578\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7882 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8160 - val_loss: 0.4752 - val_accuracy: 0.7852\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7617\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8264 - val_loss: 0.5227 - val_accuracy: 0.7773\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8264 - val_loss: 0.4609 - val_accuracy: 0.7891\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.7852\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8403 - val_loss: 0.4679 - val_accuracy: 0.7969\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8316 - val_loss: 0.4870 - val_accuracy: 0.7852\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8351 - val_loss: 0.4749 - val_accuracy: 0.7852\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8403 - val_loss: 0.4780 - val_accuracy: 0.7812\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.4646 - val_accuracy: 0.7891\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8524 - val_loss: 0.5795 - val_accuracy: 0.7461\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8333 - val_loss: 0.4635 - val_accuracy: 0.7930\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8264 - val_loss: 0.4790 - val_accuracy: 0.7852\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5167 - val_accuracy: 0.7734\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.4674 - val_accuracy: 0.8047\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.8438 - val_loss: 0.5304 - val_accuracy: 0.7773\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5000 - val_accuracy: 0.7852\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8142 - val_loss: 0.5116 - val_accuracy: 0.7734\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4368 - accuracy: 0.8281 - val_loss: 0.4662 - val_accuracy: 0.8125\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8472 - val_loss: 0.4847 - val_accuracy: 0.7852\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8212 - val_loss: 0.4679 - val_accuracy: 0.8008\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8490 - val_loss: 0.4759 - val_accuracy: 0.7930\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8455 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8403 - val_loss: 0.4885 - val_accuracy: 0.7930\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8438 - val_loss: 0.4759 - val_accuracy: 0.7930\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.8576 - val_loss: 0.5047 - val_accuracy: 0.8125\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8594 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8177 - val_loss: 0.4936 - val_accuracy: 0.8047\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3435 - accuracy: 0.8663 - val_loss: 0.4932 - val_accuracy: 0.7852\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8490 - val_loss: 0.5129 - val_accuracy: 0.7695\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8542 - val_loss: 0.4806 - val_accuracy: 0.7930\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8299 - val_loss: 0.4948 - val_accuracy: 0.7969\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8628 - val_loss: 0.4845 - val_accuracy: 0.7930\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8507 - val_loss: 0.4820 - val_accuracy: 0.7891\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8524 - val_loss: 0.5036 - val_accuracy: 0.7891\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8472 - val_loss: 0.4887 - val_accuracy: 0.7891\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8403 - val_loss: 0.4829 - val_accuracy: 0.8086\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3484 - accuracy: 0.8542 - val_loss: 0.4823 - val_accuracy: 0.7891\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3624 - accuracy: 0.8438 - val_loss: 0.5269 - val_accuracy: 0.7852\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8212 - val_loss: 0.5998 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8420 - val_loss: 0.4986 - val_accuracy: 0.8047\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8299 - val_loss: 0.4932 - val_accuracy: 0.7969\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3355 - accuracy: 0.8628 - val_loss: 0.5043 - val_accuracy: 0.7812\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8090 - val_loss: 0.5554 - val_accuracy: 0.7852\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8385 - val_loss: 0.5014 - val_accuracy: 0.7930\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8438 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.8403 - val_loss: 0.5077 - val_accuracy: 0.7852\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3375 - accuracy: 0.8594 - val_loss: 0.5218 - val_accuracy: 0.7969\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8524 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3308 - accuracy: 0.8628 - val_loss: 0.5096 - val_accuracy: 0.7891\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8368 - val_loss: 0.5529 - val_accuracy: 0.7852\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8472 - val_loss: 0.5493 - val_accuracy: 0.7812\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3708 - accuracy: 0.8333 - val_loss: 0.5152 - val_accuracy: 0.7812\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3547 - accuracy: 0.8455 - val_loss: 0.5171 - val_accuracy: 0.8008\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8507 - val_loss: 0.5157 - val_accuracy: 0.7930\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8212 - val_loss: 0.5081 - val_accuracy: 0.8086\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2990 - accuracy: 0.8819 - val_loss: 0.5040 - val_accuracy: 0.7969\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8455 - val_loss: 0.5108 - val_accuracy: 0.8008\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.8576 - val_loss: 0.5068 - val_accuracy: 0.7891\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8698 - val_loss: 0.5192 - val_accuracy: 0.8086\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3472 - accuracy: 0.8542 - val_loss: 0.5152 - val_accuracy: 0.7969\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3536 - accuracy: 0.8507 - val_loss: 0.5213 - val_accuracy: 0.7852\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8594 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8403 - val_loss: 0.5305 - val_accuracy: 0.7852\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.8733 - val_loss: 0.5653 - val_accuracy: 0.7812\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.5771 - val_accuracy: 0.7891\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8455 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3147 - accuracy: 0.8854 - val_loss: 0.5090 - val_accuracy: 0.7812\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.8455 - val_loss: 0.5330 - val_accuracy: 0.7852\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3363 - accuracy: 0.8559 - val_loss: 0.5233 - val_accuracy: 0.7969\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8646 - val_loss: 0.5887 - val_accuracy: 0.7656\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4204 - accuracy: 0.8281 - val_loss: 0.5806 - val_accuracy: 0.7969\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8316 - val_loss: 0.5463 - val_accuracy: 0.7734\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8316 - val_loss: 0.5410 - val_accuracy: 0.7891\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8368 - val_loss: 0.5395 - val_accuracy: 0.7891\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 1.model.fit\n",
    "# 2.model -> estimator -> train\n",
    "\n",
    "# 1.使用model.fit进行训练\n",
    "train_dataset = make_dataset(train_df, y_train, epochs=100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=1, shuffle=False)\n",
    "history = model.fit(train_dataset, validation_data=eval_dataset, steps_per_epoch=18, validation_steps=8, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/b6/wpgkbcmn2hxcbg2_j5904vfm0000gn/T/tmp0b4a2bqv\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/b6/wpgkbcmn2hxcbg2_j5904vfm0000gn/T/tmp0b4a2bqv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x156513b90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-913873cc31af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 参数input_fn接受一个函数，且该函数只能返回(features, labels)或dataset:(feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_data_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1190\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 419\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    420\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_learning/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# 2.model -> estimator -> train\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "def get_data_set():\n",
    "    return make_dataset(train_df, y_train, epochs=100)\n",
    "# 参数input_fn接受一个函数，且该函数只能返回(features, labels)或dataset:(feature, label)\n",
    "# estimator.train(input_fn = lambda : make_dataset(train_df, y_train, epochs=100))\n",
    "estimator.train(input_fn=get_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({sex: (None,), age: (None,), n_siblings_spouses: (None,), parch: (None,), fare: (None,), class: (None,), deck: (None,), embark_town: (None,), alone: (None,)}, (None,)), types: ({sex: tf.string, age: tf.float64, n_siblings_spouses: tf.int32, parch: tf.int32, fare: tf.float64, class: tf.string, deck: tf.string, embark_town: tf.string, alone: tf.string}, tf.int32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = get_data_set()\n",
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (machine_learning)",
   "language": "python",
   "name": "pycharm-b74d5558"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
