{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'training', 'monkey_labels.txt', 'validation']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"10-monkey-species\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "['n0', 'n7', 'n9', 'n8', 'n6', 'n1', 'n4', 'n3', 'n2', 'n5']\n",
      "['n0', 'n7', 'n9', 'n8', 'n6', 'n1', 'n4', 'n3', 'n2', 'n5']\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"10-monkey-species/training/training\"\n",
    "valid_dir = \"10-monkey-species/validation/validation\"\n",
    "label_file = \"10-monkey-species/monkey_labels.txt\"\n",
    "print(os.path.exists(train_dir))\n",
    "print(os.path.exists(valid_dir))\n",
    "print(os.path.exists(label_file))\n",
    "\n",
    "print(os.listdir(train_dir))\n",
    "print(os.listdir(valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label     Latin Name              Common Name                     \\\n",
      "0  n0         alouatta_palliata\\t    mantled_howler                   \n",
      "1  n1        erythrocebus_patas\\t    patas_monkey                     \n",
      "2  n2        cacajao_calvus\\t        bald_uakari                      \n",
      "3  n3        macaca_fuscata\\t        japanese_macaque                 \n",
      "4  n4       cebuella_pygmea\\t        pygmy_marmoset                   \n",
      "5  n5       cebus_capucinus\\t        white_headed_capuchin            \n",
      "6  n6       mico_argentatus\\t        silvery_marmoset                 \n",
      "7  n7      saimiri_sciureus\\t        common_squirrel_monkey           \n",
      "8  n8       aotus_nigriceps\\t        black_headed_night_monkey        \n",
      "9  n9       trachypithecus_johnii    nilgiri_langur                   \n",
      "\n",
      "    Train Images    Validation Images  \n",
      "0             131                  26  \n",
      "1             139                  28  \n",
      "2             137                  27  \n",
      "3             152                  30  \n",
      "4             131                  26  \n",
      "5             141                  28  \n",
      "6             132                  26  \n",
      "7             142                  28  \n",
      "8             133                  27  \n",
      "9             132                  26  \n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(label_file, header=0)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 10 classes.\n",
      "Found 272 images belonging to 10 classes.\n",
      "1098 1098\n"
     ]
    }
   ],
   "source": [
    "# 定义图片大小\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "batch_size = 24\n",
    "num_classes = 10\n",
    "\n",
    "# 创建数据generator（针对图片的api）\n",
    "# 里面的参数都是做数据增强的\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = keras.applications.resnet50.preprocess_input,   # 针对resnet50的预处理函数，用于做归一化到(-1, 1)\n",
    "                                                             rotation_range = 40, # 旋转角度，随机旋转（-40， 40）度\n",
    "                                                             width_shift_range = 0.2,   # 水平位移 \n",
    "                                                             height_shift_range = 0.2,  # 垂直位移\n",
    "                                                             shear_range = 0.2, # 剪切强度\n",
    "                                                             zoom_range = 0.2, # 缩放强度\n",
    "                                                             horizontal_flip = True, # 是否随机做水平翻转\n",
    "                                                             fill_mode = 'nearest'  # 填充像素策略\n",
    "                                                              )\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 7,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = 'categorical' # 使用one_hot编码\n",
    "                                                    )\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = keras.applications.resnet50.preprocess_input)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, \n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 7,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = 'categorical' # 使用one_hot编码\n",
    "                                                    )\n",
    "\n",
    "train_num = train_generator.samples  # 训练集数据数量\n",
    "valid_num = train_generator.samples\n",
    "print(train_num, valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 224, 224, 3) (24, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "(24, 224, 224, 3) (24, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 从generator中取数据\n",
    "for i in range(2):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用resnet50模型做迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      " 3244032/94765736 [>.............................] - ETA: 27:02:16"
     ]
    }
   ],
   "source": [
    "resnet50_fine_tune = keras.models.Sequential()\n",
    "resnet50_fine_tune.add(keras.applications.ResNet50(include_top=False,  # 去掉最后一层即输出层（resnet50解决的是1000分类，而我们的是10分类，所以要去掉重新定义）\n",
    "                                                   pooling='avg',      # resnet50 倒数第二层的输出是一个卷积层的输出，是一个三维矩阵，因此需要：1.pooling掉两层 2.做flatten（pooling='None'）两种方法选一个\n",
    "                                                   weights='imagenet'))# weights=['None', 'imagenet'], None: 从头开始训练, imagenet: 下载一个训练好的模型初始化网络结构\n",
    "resnet50_fine_tune.add(keras.layers.Dense(num_classes, activation='softmax')) # 添加输出层\n",
    "resnet50_fine_tune.layers[0].trainable = False   # 将网络结构第一层(resnet50这一层)fix住，不能训练，只训练输出层(这里resnet 50层的网络结构只当成一层)\n",
    "\n",
    "resnet50_fine_tune.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = resnet50_fine_tune.fit_generator(train_generator, \n",
    "                                           steps_per_epoch = train_num // batch_size, \n",
    "                                           epochs=epochs, \n",
    "                                           validation_data=valid_generator,\n",
    "                                           validation_steps=valid_num // batch_size\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, label, epochs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val'+label] = history.history['val_'+label]\n",
    "    pd.DataFrame(data).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history, 'accuracy', epochs, 0, 1)\n",
    "plot_learning_curves(history, 'loss', epochs, 0, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使resnet50后几层可以训练，前几层不能训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = keras.applications.ResNet50(include_top=False,  # 去掉最后一层即输出层（resnet50解决的是1000分类，而我们的是10分类，所以要去掉重新定义）\n",
    "                                       pooling='avg',      # resnet50 倒数第二层的输出是一个卷积层的输出，是一个三维矩阵，因此需要：1.pooling掉两层 2.做flatten（pooling='None'）两种方法选一个\n",
    "                                       weights='imagenet'))# weights=['None', 'imagenet'], None: 从头开始训练, imagenet: 下载一个训练好的模型初始化网络结构\n",
    "\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet50.layers[0: -5]:\n",
    "    layer.trainable = False\n",
    "resnet50_new = keras.layers.Sequential([\n",
    "    resnet50,\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "resnet50_new.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "resnet50_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = resnet50_fine_tune.fit_generator(train_generator, \n",
    "                                           steps_per_epoch = train_num // batch_size, \n",
    "                                           epochs=epochs, \n",
    "                                           validation_data=valid_generator,\n",
    "                                           validation_steps=valid_num // batch_size\n",
    "                                           )\n",
    "# 此时效果会变差一点，原因：\n",
    "# 1.resnet后几层可以训练增加了可训练参数量，收敛需要更长的时间\n",
    "# 2.resnet后几层已经训练好的，最后一次层是没有经过训练的，此时如果learning_rate较大，训练好的参数会被破坏掉，恢复到较好的状态需要较长的时间\n",
    "# 因此需要减小learning_rate，增加迭代次数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
